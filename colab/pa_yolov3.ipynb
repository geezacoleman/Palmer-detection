{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MPjfT5NrKQ"
   },
   "source": [
    "# Palmer Amaranth (Amaranthus palmeri) Growth Stage Detection\n",
    "This Google Colab notebook has been adapted from the **official YOLOv3 notebook** by **Ultralytics** to train and evaluate YOLOv3 on the Palmer amaranth Growth Stage (PAGS8) dataset. The dataset is available for download from [Weed-AI](). Prior to use, the dataset should be setup using the instructions from the official repository.\n",
    "\n",
    "It accompanies the preprint: **Multi-growth stage plant recognition: a case study of Palmer amaranth (Amaranthus palmeri) in cotton (Gossypium hirsutum)** available on [arXiv](https://arxiv.org/abs/2307.15816). Please consider citing this preprint if you use the work in your research.\n",
    "\n",
    "Models were trained using Google Colab Pro+ with access to an NVIDIA A100-SXM4-40GB.\n",
    "\n",
    "This notbook consists of five parts:\n",
    "1. Setup\n",
    "2. Training\n",
    "3. Evaluation\n",
    "4. Inference\n",
    "5. Additional information\n",
    "\n",
    "For additional documentation, training options and inference procedures please visit the official Ultralytics repository. (Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)\n",
    "\n",
    "<img src=\"https://github.com/geezacoleman/Palmer-detection/assets/51358498/6040227e-a072-43bf-a789-72e0833f3168\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Clone repo, install dependencies and check PyTorch and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17928,
     "status": "ok",
     "timestamp": 1675101476551,
     "user": {
      "displayName": "Guy Coleman",
      "userId": "03981860468374888786"
     },
     "user_tz": -60
    },
    "id": "lSNFzpLF4d8e",
    "outputId": "a3922e07-4b0f-4316-d847-c8625f9bc35b"
   },
   "outputs": [],
   "source": [
    "# mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1675101674548,
     "user": {
      "displayName": "Guy Coleman",
      "userId": "03981860468374888786"
     },
     "user_tz": -60
    },
    "id": "xcvTZxBP4dyU",
    "outputId": "1c5fa485-9c4b-4227-8fac-61dc9904ef5f",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Assumes you have already cloned the Palmer-detection repository\n",
    "%cd '/content/drive/MyDrive/Palmer-detection'\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "DATE = datetime.now().strftime('%Y%m%d')\n",
    "IMAGE_SIZE = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3422,
     "status": "ok",
     "timestamp": 1675101689268,
     "user": {
      "displayName": "Guy Coleman",
      "userId": "03981860468374888786"
     },
     "user_tz": -60
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "6c26c85f-a829-407a-f6ed-11ff7fe34476"
   },
   "outputs": [],
   "source": [
    "%cd yolov3\n",
    "%pip install -qr requirements.txt  # install requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY2VXXXu74w5"
   },
   "source": [
    "# 2. Training\n",
    "Train a YOLOv3 model on the [COCO128](https://www.kaggle.com/ultralytics/coco128) dataset with `--data coco128.yaml`, starting from pretrained `--weights yolov3.pt`, or from randomly initialized `--weights '' --cfg yolov3yaml`.\n",
    "\n",
    "- **Pretrained [Models](https://github.com/ultralytics/yolov3/tree/master/models)** are downloaded\n",
    "automatically from the [latest YOLOv3 release](https://github.com/ultralytics/yolov3/releases)\n",
    "- **[Datasets](https://github.com/ultralytics/yolov3/tree/master/data)** available for autodownload include: [COCO](https://github.com/ultralytics/yolov3/blob/master/data/coco.yaml), [COCO128](https://github.com/ultralytics/yolov3/blob/master/data/coco128.yaml), [VOC](https://github.com/ultralytics/yolov3/blob/master/data/VOC.yaml), [Argoverse](https://github.com/ultralytics/yolov3/blob/master/data/Argoverse.yaml), [VisDrone](https://github.com/ultralytics/yolov3/blob/master/data/VisDrone.yaml), [GlobalWheat](https://github.com/ultralytics/yolov3/blob/master/data/GlobalWheat2020.yaml), [xView](https://github.com/ultralytics/yolov3/blob/master/data/xView.yaml), [Objects365](https://github.com/ultralytics/yolov3/blob/master/data/Objects365.yaml), [SKU-110K](https://github.com/ultralytics/yolov3/blob/master/data/SKU-110K.yaml).\n",
    "- **Training Results** are saved to `runs/train/` with incrementing run directories, based on the parameters you set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weights and Biases\n",
    "WandB is an excellent tool to track/monitor training performance, particularly across large training runs. While optional, it is recommended, however, requires setting up an account and logging in below.\n",
    "\n",
    "Only run this cell if you plan on using WandB."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "executionInfo": {
     "elapsed": 24560,
     "status": "ok",
     "timestamp": 1670359742110,
     "user": {
      "displayName": "Guy Coleman",
      "userId": "03981860468374888786"
     },
     "user_tz": -60
    },
    "id": "2fLAV42oNb7M",
    "outputId": "402446f3-36de-4f0c-dc92-5a0feb54ccfa"
   },
   "outputs": [],
   "source": [
    "# Weights & Biases  (optional)\n",
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Training all models, folds and classes\n",
    "models = ['-tiny', '', '-spp'] # all three classes\n",
    "classes = ['1', '8']\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# warning - running this will train 3 x 2 x 5 models (30 total)\n",
    "for model in models:\n",
    "  for class_num in classes:\n",
    "    for fold in folds:\n",
    "      yaml_path = f'{class_num}cls_fold_{fold}.yaml'\n",
    "      full_name = f'{DATE}_yolov3{model}_B8_F0_{model}_{class_num}'\n",
    "      \n",
    "      !python train.py --img {IMAGE_SIZE} --cfg yolov3{model}.yaml --hyp hyp.scratch-low.yaml --batch 8 --epochs 30 --data data/{yaml_path} --weights yolov3{model}.pt --name {full_name}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Evaluation\n",
    "This will run over all the runs within the train directory and run the evaluation on them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "%cd '/content/drive/My Drive/Palmer-detection/yolov3'\n",
    "train_path = \"/content/drive/My Drive/Palmer-detection/yolov3/runs/train\"\n",
    "\n",
    "for run_name in tqdm(os.listdir(train_path)):\n",
    "  if 'v3' not in run_name:\n",
    "    print(f'skipping {run_name}')\n",
    "  \n",
    "  class_num = run_name.split(\"_\")[4]\n",
    "  fold = run_name.split(\"_\")[3][-1]\n",
    "  yaml_path = f\"{class_num}cls_fold_{fold}.yaml\"\n",
    "    \n",
    "  !python val.py --img {IMAGE_SIZE} --weights runs/train/{run_name}/weights/best.pt --data data/{yaml_path} --name {run_name} --task 'test' --batch-size 8 --iou-thres 0.6 --conf-thres 0.001 --verbose --save-metrics\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Inference"
   ],
   "metadata": {
    "id": "oTMSOqYEIqJS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd '/content/drive/My Drive/Palmer-detection/yolov5'\n",
    "models = ['-tiny', '', '-spp']\n",
    "yaml_path = f\"fold_0_pa_8cls.yaml\"\n",
    "source = r\"datasets/test\"\n",
    "\n",
    "for model in models:\n",
    "  run_name = f'{DATE}_yolov5{model}5_B8_F0_8cls'\n",
    "  !python detect.py --img {IMAGE_SIZE} --weights runs/train/done/{run_name}/weights/best.pt --source {source} --name {run_name} --iou-thres 0.45 --conf-thres 0.25"
   ],
   "metadata": {
    "id": "ZhsGqK8MIqBe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15glLzbQx5u0"
   },
   "source": [
    "# 5. Additional Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WPvRbS5Swl6"
   },
   "source": [
    "## Local Logging\n",
    "\n",
    "All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, if a name isn't provided. View train and val jpgs to see mosaics, labels, predictions and augmentation effects. Note an Ultralytics **Mosaic Dataloader** is used for training (shown below), which combines 4 images into 1 mosaic during training.\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/131255960-b536647f-7c61-4f60-bbc5-cb2544d71b2a.jpg\" width=\"700\">  \n",
    "`train_batch0.jpg` shows train batch 0 mosaics and labels\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/131256748-603cafc7-55d1-4e58-ab26-83657761aed9.jpg\" width=\"700\">  \n",
    "`test_batch0_labels.jpg` shows val batch 0 labels\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/131256752-3f25d7a5-7b0f-4bb3-ab78-46343c3800fe.jpg\" width=\"700\">  \n",
    "`test_batch0_pred.jpg` shows val batch 0 _predictions_\n",
    "\n",
    "Training results are automatically logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and [CSV](https://github.com/ultralytics/yolov5/pull/4148) as `results.csv`, which is plotted as `results.png` (below) after training completes. You can also plot any `results.csv` file manually:\n",
    "\n",
    "```python\n",
    "from utils.plots import plot_results \n",
    "plot_results('path/to/results.csv')  # plot 'results.csv' as 'results.png'\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/ultralytics/yolov3/blob/master/tutorial.ipynb",
     "timestamp": 1668609539487
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
